{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "from bert import BERTClassifier\n",
    "from training import train_model, evaluate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# VOCABS\n",
    "TEXT = data.Field(\n",
    "    batch_first = True,\n",
    "    use_vocab = False,\n",
    "    tokenize = tokenize_and_cut,\n",
    "    preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "    init_token = init_token_idx,\n",
    "    eos_token = eos_token_idx,\n",
    "    pad_token = pad_token_idx,\n",
    "    unk_token = unk_token_idx\n",
    ")\n",
    "\n",
    "LABEL = data.LabelField()\n",
    "\n",
    "# load train, validation and test data from corresponding CSV files\n",
    "train_data, valid_data = data.TabularDataset.splits(\n",
    "    path='../data', \n",
    "    train='spam-train.csv',\n",
    "    validation='spam-valid.csv',\n",
    "    format='csv', \n",
    "    skip_header=True,\n",
    "    fields=[('label', LABEL),('text', TEXT)]\n",
    ")\n",
    "\n",
    "# Build vocabulary for labels\n",
    "LABEL.build_vocab(train_data)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Define iterators to iterate through different datasets \n",
    "# during training and testing model\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# model hyper-parameters\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Create the BERT model\n",
    "model = BERTClassifier(bert, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "\n",
    "# freeze all bert parameters\n",
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#################################\n",
    "### DEFINE LOSS AND OPTIMIZER ###\n",
    "#################################\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# move the model and the loss function to GPU if there is a GPU \n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#############\n",
    "### TRAIN ###\n",
    "#############\n",
    "fname=f'models/bert-{N_LAYERS}-{HIDDEN_DIM}.pt'\n",
    "\n",
    "train_model(\n",
    "    model, \n",
    "    device,\n",
    "    train_iterator, \n",
    "    valid_iterator, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    scheduler, \n",
    "    n_epochs=5, \n",
    "    fname=fname)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Valid Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.069</td>\n",
       "      <td>91.41</td>\n",
       "      <td>98.32</td>\n",
       "      <td>1m 6s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.059</td>\n",
       "      <td>98.71</td>\n",
       "      <td>98.75</td>\n",
       "      <td>1m 10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.047</td>\n",
       "      <td>98.96</td>\n",
       "      <td>98.91</td>\n",
       "      <td>1m 11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.051</td>\n",
       "      <td>99.08</td>\n",
       "      <td>98.91</td>\n",
       "      <td>1m 21s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.048</td>\n",
       "      <td>99.16</td>\n",
       "      <td>98.91</td>\n",
       "      <td>1m 32s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch Train Loss Valid Loss Train Acc Valid Acc    Time\n",
       "0     1      0.234      0.069     91.41     98.32   1m 6s\n",
       "1     2      0.052      0.059     98.71     98.75  1m 10s\n",
       "2     3      0.033      0.047     98.96     98.91  1m 11s\n",
       "3     4      0.031      0.051     99.08     98.91  1m 21s\n",
       "4     5      0.027      0.048     99.16     98.91  1m 32s"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "test_loss, test_acc = evaluate(model, valid_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Testing on test dataset...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Validation: | Loss=0.0114 | Acc=1.0000 |: 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| Test Loss: 0.047 | Test Acc: 98.91% |\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/spam-train.csv')\n",
    "train_labels = train_df['label']\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(class_wts)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.57831603 3.6921944 ]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/razavi/Documents/mygithub/Deep-Learning-for-NLP/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=['ham' 'spam'], y=0       ham\n",
      "1       ham\n",
      "2       ham\n",
      "3       ham\n",
      "4       ham\n",
      "       ... \n",
      "5009    ham\n",
      "5010    ham\n",
      "5011    ham\n",
      "5012    ham\n",
      "5013    ham\n",
      "Name: label, Length: 5014, dtype: object as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# convert class weights to tensor\n",
    "weights = torch.tensor(class_wts, dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "# cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "fname=f'models/bert-balanced-{N_LAYERS}-{HIDDEN_DIM}.pt'\n",
    "\n",
    "train_model(\n",
    "    model, \n",
    "    device,\n",
    "    train_iterator, \n",
    "    valid_iterator, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    scheduler, \n",
    "    n_epochs=5, \n",
    "    fname=fname)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Valid Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.106</td>\n",
       "      <td>97.56</td>\n",
       "      <td>98.16</td>\n",
       "      <td>1m 4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.084</td>\n",
       "      <td>98.48</td>\n",
       "      <td>98.44</td>\n",
       "      <td>1m 15s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.099</td>\n",
       "      <td>99.34</td>\n",
       "      <td>97.66</td>\n",
       "      <td>1m 24s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.100</td>\n",
       "      <td>99.18</td>\n",
       "      <td>97.03</td>\n",
       "      <td>1m 35s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.117</td>\n",
       "      <td>99.57</td>\n",
       "      <td>95.78</td>\n",
       "      <td>1m 23s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch Train Loss Valid Loss Train Acc Valid Acc    Time\n",
       "0     1      0.089      0.106     97.56     98.16   1m 4s\n",
       "1     2      0.045      0.084     98.48     98.44  1m 15s\n",
       "2     3      0.028      0.099     99.34     97.66  1m 24s\n",
       "3     4      0.026      0.100     99.18     97.03  1m 35s\n",
       "4     5      0.012      0.117     99.57     95.78  1m 23s"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test_loss, test_acc = evaluate(model, valid_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Validation: | Loss=0.0074 | Acc=1.0000 |: 100%|██████████| 5/5 [00:02<00:00,  1.96it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| Test Loss: 0.084 | Test Acc: 98.44% |\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "bb146c5d9fb2de7bb24b6c8c0d0cf94a96a306053df0ca0e841e97387004e95e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}