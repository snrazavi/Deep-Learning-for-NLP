{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819b78f1",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1809930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from utils import display_classification_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6805e51",
   "metadata": {},
   "source": [
    "### Read data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b46fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"../data/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae45450c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9bb91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n",
      "4825\n"
     ]
    }
   ],
   "source": [
    "print(len(data_df[data_df['label'] == 'spam']))\n",
    "print(len(data_df[data_df['label'] == 'ham']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ce37e",
   "metadata": {},
   "source": [
    "### Split data to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9b6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(data_df, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058877fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5014 558\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9adb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/spam-train.csv', index=False)\n",
    "valid_df.to_csv('../data/spam-valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63335ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Convey my regards to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[‰Û_] anyway, many good evenings to u! s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>My sort code is  and acc no is . The bank is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry i din lock my keypad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Tyler (getting an 8th) has to leave not long a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>ham</td>\n",
       "      <td>K. I will sent it again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sday only joined.so training we started today:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey...Great deal...Farm tour 9am to 5pm $95/pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "0     ham                           Convey my regards to him\n",
       "1     ham           [‰Û_] anyway, many good evenings to u! s\n",
       "2     ham  My sort code is  and acc no is . The bank is n...\n",
       "3     ham                        Sorry i din lock my keypad.\n",
       "4    spam  Hi babe its Chloe, how r u? I was smashed on s...\n",
       "..    ...                                                ...\n",
       "553   ham  Tyler (getting an 8th) has to leave not long a...\n",
       "554   ham                            K. I will sent it again\n",
       "555   ham    Sday only joined.so training we started today:)\n",
       "556  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "557   ham  Hey...Great deal...Farm tour 9am to 5pm $95/pa...\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/spam-train.csv')\n",
    "valid_df = pd.read_csv('../data/spam-valid.csv')\n",
    "\n",
    "valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f0f49",
   "metadata": {},
   "source": [
    "### Using torchtext\n",
    "1. Define fields\n",
    "2. Define datasets (train, validation, test)\n",
    "3. Build vocabulary for each field\n",
    "3. Define iterators for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf3ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razavi/Documents/mygithub/NLP/venv/lib/python3.6/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9348354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'ham', 'text': ['Gud', 'gud', '..', 'k', ',', 'chikku', 'tke', 'care', '..', 'sleep', 'well', 'gud', 'nyt']}\n",
      "{'label': 'ham', 'text': ['Convey', 'my', 'regards', 'to', 'him']}\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = data.TabularDataset.splits(\n",
    "    path=\"../data/\",\n",
    "    train='spam-train.csv',\n",
    "    validation='spam-valid.csv',\n",
    "    format='CSV',\n",
    "    skip_header=True,\n",
    "    fields=[('label', LABEL), ('text', TEXT)]\n",
    ")\n",
    "\n",
    "print(vars(train_data[0]))\n",
    "print(vars(valid_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e972295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'ham': 0, 'spam': 1})\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary for texts\n",
    "vocab_size = 20_000\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                 max_size=vocab_size)\n",
    "\n",
    "# Build vocabulary for labels\n",
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ae3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator = data.BucketIterator(train_data, batch_size, sort_key=lambda x: len(x.text), device=device)\n",
    "valid_iterator = data.BucketIterator(\n",
    "    valid_data, \n",
    "    batch_size, \n",
    "    sort_key=lambda x: len(x.text), \n",
    "    device=device,\n",
    "    train=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ffc4c1",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04370776",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FastText Model ###\n",
    "class FastText(nn.Module):\n",
    "    \"\"\" A simple model which first embeds the words in the input text and then averages them\n",
    "        to create an embedding for the text. Then by using a linear layer, the text is mapped\n",
    "        into one of the desired classess.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \"\"\" Constructor\n",
    "        \n",
    "            Inputs:\n",
    "                - vocab_size: number of unique words in the vocabulary\n",
    "                - embedding_dim: size of embedding vectors\n",
    "                - output_dim: number of classes\n",
    "                - pad_idx: index of <PAD> token in the vocabulary\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)      # embedded = [sent len, batch size, emb dim]\n",
    "        embedded = embedded.permute(1, 0, 2) # embedded = [batch size, sent len, emb dim]\n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) # pooled = [batch size, embedding_dim]\n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f38ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(vocab_size=vocab_size, embedding_dim=100, output_dim=2, pad_idx=0)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a95978",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09808076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.0466 | Train Acc = 98.54 | Valid Loss = 0.0994 | Valid Acc = 95.89\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    \n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    \n",
    "    for batch in train_iterator:\n",
    "        # forward step\n",
    "        prediction = model(batch.text)\n",
    "        loss = criterion(prediction, batch.label)\n",
    "        acc = (prediction.argmax(1) == batch.label).float().mean()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc\n",
    "        \n",
    "        print(f'Epoch {i+1} | Training | Loss = {loss:.4f} | Acc = {acc*100.0:.2f}')\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    valid_loss, valid_acc = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            # forward step\n",
    "            prediction = model(batch.text)\n",
    "            loss = criterion(prediction, batch.label)\n",
    "            acc = (prediction.argmax(1) == batch.label).float().mean()\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += acc\n",
    "\n",
    "            print(f'Epoch {i+1} | Validation | Loss = {loss:.4f} | Acc = {acc*100.0:.2f}')\n",
    "            clear_output(wait=True)\n",
    "       \n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    train_loss /= len(train_iterator)\n",
    "    train_acc /= len(train_iterator)\n",
    "    valid_loss /= len(valid_iterator)\n",
    "    valid_acc /= len(valid_iterator)\n",
    "    \n",
    "    print(f'Train Loss = {train_loss:.4f} | Train Acc = {train_acc*100:.2f} | Valid Loss = {valid_loss:.4f} | Valid Acc = {valid_acc*100:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5024bf8",
   "metadata": {},
   "source": [
    "### Testing model on user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95aafe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = [t.text for t in nlp(sentence)]\n",
    "    \n",
    "    # numericalize\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokens]\n",
    "    \n",
    "    # convert to torch tensor and add batch dimension\n",
    "    indexed = torch.LongTensor(indexed).unsqueeze(1).to(device)\n",
    "    \n",
    "    # predict the label\n",
    "    prediction = model(indexed)\n",
    "    \n",
    "    return LABEL.vocab.itos[prediction.argmax(1).item()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94249489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     \u001b[41mAre you ready for the tea party????? It's gonna be wild\u001b[m\n",
      "spam    \u001b[43mURGENT Reply to this message for GUARANTEED FREE TEA\u001b[m\n"
     ]
    }
   ],
   "source": [
    "docs = [\"Are you ready for the tea party????? It's gonna be wild\",\n",
    "        \"URGENT Reply to this message for GUARANTEED FREE TEA\"]\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    label = predict(model, doc)\n",
    "    display_classification_result(doc, label, LABEL.vocab.stoi[label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
